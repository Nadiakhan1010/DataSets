{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NB-WDBC.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs2VJyHyy9Mx"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
        "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
        "import seaborn as sns # used for plot interactive graph. I like it most for plot\n",
        "%matplotlib inline\n",
        "from sklearn.linear_model import LogisticRegression # to apply the Logistic regression\n",
        "from sklearn.model_selection import train_test_split # to split the data into two parts\n",
        "#from sklearn.cross_validation import KFold # use for cross validation\n",
        "from sklearn.model_selection import GridSearchCV# for tuning parameter\n",
        "from sklearn.ensemble import RandomForestClassifier # for random forest classifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm # for Support Vector Machine\n",
        "from sklearn import metrics #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQsyZb9kzVVm",
        "outputId": "4317cf61-608d-405f-df70-7b122279bffb"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/mhmmd-nauman/DataSets/master/wdbc/csv/wdbc-complete.csv\")\n",
        "\n",
        "print(df.head)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of      Mean Radius  Mean Texture  ...  Worst Fractal Dimension  Diagnosis\n",
            "0          17.99         10.38  ...                  0.11890          M\n",
            "1          20.57         17.77  ...                  0.08902          M\n",
            "2          19.69         21.25  ...                  0.08758          M\n",
            "3          11.42         20.38  ...                  0.17300          M\n",
            "4          20.29         14.34  ...                  0.07678          M\n",
            "..           ...           ...  ...                      ...        ...\n",
            "564        21.56         22.39  ...                  0.07115          M\n",
            "565        20.13         28.25  ...                  0.06637          M\n",
            "566        16.60         28.08  ...                  0.07820          M\n",
            "567        20.60         29.33  ...                  0.12400          M\n",
            "568         7.76         24.54  ...                  0.07039          B\n",
            "\n",
            "[569 rows x 31 columns]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBdAbI6Dzr3F"
      },
      "source": [
        "#df=df[df.columns[:-1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "YV5H89aF0E5X",
        "outputId": "f29e0a3d-659a-4859-8c02-f94b7920adeb"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean Radius</th>\n",
              "      <th>Mean Texture</th>\n",
              "      <th>Mean Perimeter</th>\n",
              "      <th>Mean Area</th>\n",
              "      <th>Mean Smoothness</th>\n",
              "      <th>Mean Compactness</th>\n",
              "      <th>Mean Concavity</th>\n",
              "      <th>Mean Concave Points</th>\n",
              "      <th>Mean Symmetry</th>\n",
              "      <th>Mean Fractal Dimension</th>\n",
              "      <th>Radius SE</th>\n",
              "      <th>Texture SE</th>\n",
              "      <th>Perimeter SE</th>\n",
              "      <th>SE Area</th>\n",
              "      <th>SE Smoothness</th>\n",
              "      <th>SE Compactness</th>\n",
              "      <th>SE Concavity</th>\n",
              "      <th>SE Concave Points</th>\n",
              "      <th>SE Symmetry</th>\n",
              "      <th>SE Fractal Dimension</th>\n",
              "      <th>Worst Radius</th>\n",
              "      <th>Worst Texture</th>\n",
              "      <th>Worst Perimeter</th>\n",
              "      <th>Worst Area</th>\n",
              "      <th>Worst Smoothness</th>\n",
              "      <th>Worst Compactness</th>\n",
              "      <th>Worst Concavity</th>\n",
              "      <th>Worst Concave Points</th>\n",
              "      <th>Worst Symmetry</th>\n",
              "      <th>Worst Fractal Dimension</th>\n",
              "      <th>Diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Mean Radius  Mean Texture  ...  Worst Fractal Dimension  Diagnosis\n",
              "0        17.99         10.38  ...                  0.11890          M\n",
              "1        20.57         17.77  ...                  0.08902          M\n",
              "2        19.69         21.25  ...                  0.08758          M\n",
              "3        11.42         20.38  ...                  0.17300          M\n",
              "4        20.29         14.34  ...                  0.07678          M\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URIZMK2d0Yd9"
      },
      "source": [
        "#df['Application Status'] = df['Application Status'].map({'Complete':1,'NotComplete':0})\n",
        "#df['Offered'] = df['Offered'].map({'Yes':1,'No':0})\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "#df['Application Status'] = labelencoder_X_1.fit_transform(df['Application Status'])\n",
        "#df['Domicile'] = labelencoder_X_1.fit_transform(df['Domicile'])\n",
        "#df['Gender'] = labelencoder_X_1.fit_transform(df['Gender'])\n",
        "#df['Province'] = labelencoder_X_1.fit_transform(df['Province'])\n",
        "df['Diagnosis'] = labelencoder_X_1.fit_transform(df['Diagnosis'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjWjNBGXBqRN"
      },
      "source": [
        "def clean_dataset(df):\n",
        "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
        "    df.dropna(inplace=True)\n",
        "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    return df[indices_to_keep].astype(np.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hsgSaOfBrFL"
      },
      "source": [
        "df = clean_dataset(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "qrhnSlQR0dfV",
        "outputId": "2a4738aa-da10-4b6d-e01b-2ad3c8de577f"
      },
      "source": [
        "sns.countplot(df['Diagnosis'],label=\"Count\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb3ce73d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2Yo2nH01T4N"
      },
      "source": [
        "X = df.drop('Diagnosis',axis=1)\n",
        "y = df.Diagnosis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4ZZW3Sd4sRP",
        "outputId": "9a320cdc-d038-4dfd-b105-304e21642d9b"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                   y,\n",
        "                                                   test_size=0.3,\n",
        "                                                   random_state=0)\n",
        "print('X_train: ',X_train.shape)\n",
        "print('X_test: ',X_test.shape)\n",
        "print('y_train: ',y_train.shape)\n",
        "print('y_test: ',y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:  (398, 30)\n",
            "X_test:  (171, 30)\n",
            "y_train:  (398,)\n",
            "y_test:  (171,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATnVRHmfCkND",
        "outputId": "0e31bd73-339b-4e4c-df69-6122a6ec8429"
      },
      "source": [
        "#NB\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9239766081871345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMMUUPHpCz39"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "Sp = tn / (tn+fp)\n",
        "Sn = tp/(tp + fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOytLG2xC00V",
        "outputId": "732a9c1d-ebd7-4bf5-f146-b023ed275395"
      },
      "source": [
        "print(cm)\n",
        "print(Sp)\n",
        "print(Sn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[101   7]\n",
            " [  6  57]]\n",
            "0.9351851851851852\n",
            "0.9047619047619048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k05X1KeNC4CD",
        "outputId": "32435a78-326e-4eaf-eb10-5f52903ea3dc"
      },
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "cohen_score = cohen_kappa_score(y_test, y_pred)\n",
        "print(cohen_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5819477434679334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "najJDKoj4xaO",
        "outputId": "4851fcf1-c821-4dd9-d621-596d36cfe08d"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "models = []\n",
        "models.append(( ' LR ' , LogisticRegression()))\n",
        "#models.append(( ' LDA ' , LinearDiscriminantAnalysis()))\n",
        "models.append(( ' KNN ' , KNeighborsClassifier()))\n",
        "models.append(( ' RF ' , RandomForestClassifier()))\n",
        "models.append(( ' NB ' , GaussianNB()))\n",
        "#models.append(( ' SVM ' , SVC()))\n",
        "\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "for name, model in models:\n",
        "    Kfold = KFold(n_splits=10, random_state=0)\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=Kfold, scoring= 'accuracy')\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std());\n",
        "    print(msg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " LR : 0.949095 (0.035320)\n",
            " KNN : 0.919683 (0.035653)\n",
            " RF : 0.976471 (0.022866)\n",
            " NB : 0.941252 (0.035118)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu9m5P3WJZem",
        "outputId": "0a6626c2-69c9-4ded-84ac-219e0404ee5f"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "pipelines = []\n",
        "#pipelines.append(( ' ScaledLR ' , Pipeline([( 'Scaler' , StandardScaler()),( ' LR ' ,\n",
        "#LogisticRegression())])))\n",
        "#pipelines.append(( ' ScaledLDA ' , Pipeline([( 'Scaler' , StandardScaler()),( ' LDA ' ,\n",
        "#LinearDiscriminantAnalysis())])))\n",
        "pipelines.append(( ' ScaledKNN ' , Pipeline([( ' Scaler ' , StandardScaler()),( ' KNN ' ,\n",
        "KNeighborsClassifier())])))\n",
        "pipelines.append(( ' ScaledRF ' , Pipeline([( ' Scaler ' , StandardScaler()),( ' RandomForest ' ,\n",
        "RandomForestClassifier())])))\n",
        "pipelines.append(( ' ScaledNB ' , Pipeline([( ' Scaler ' , StandardScaler()),( ' NB ' ,\n",
        "GaussianNB())])))\n",
        "#pipelines.append(( ' ScaledSVM ' , Pipeline([( ' Scaler' , StandardScaler()),( ' SVM ' , SVC())])))\n",
        "\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "for name, model in pipelines:\n",
        "    kfold = KFold(n_splits=10, random_state=0)\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ScaledKNN : 0.964744 (0.022893)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " ScaledRF : 0.982353 (0.018498)\n",
            " ScaledNB : 0.933446 (0.033072)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}