{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WDBC- Bagging with Scikit-learn.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GUkpvePapfA"
      },
      "outputs": [],
      "source": [
        "# check scikit-learn version\n",
        "import sklearn\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6kcmPFyZjLsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate bagging algorithm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/mhmmd-nauman/DataSets/master/black-box-models/CP-Nets/wdbc/original%20ds/wdbc-complete-original.csv')\n",
        "X = data.iloc[:, 1:30].values\n",
        "y = data['Diagnosis']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3 ,random_state=0)\n",
        "# define the model\n",
        "model = BaggingClassifier()\n",
        "# evaluate the model\n",
        "#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "#n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "# report performance\n",
        "#print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "id": "ByyGxPGafqfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "6AwfwOEk_X9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "cRV8mL2mBVes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "Sp = tn / (tn+fp)\n",
        "Sn = tp/(tp + fn)"
      ],
      "metadata": {
        "id": "XcYh70PH_Dw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cm)\n",
        "print(Sp)\n",
        "print(Sn)"
      ],
      "metadata": {
        "id": "fUbnffLd_Kf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# explore bagging ensemble number of trees effect on performance\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
        "\treturn X, y\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\t# define number of trees to consider\n",
        "\tn_trees = [10, 50, 100, 500, 500]\n",
        "\tfor n in n_trees:\n",
        "\t\tmodels[str(n)] = BaggingClassifier(n_estimators=n)\n",
        "\treturn models\n",
        "\n",
        "# evaluate a given model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\t# define the evaluation procedure\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\t# evaluate the model and collect the results\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\treturn scores\n",
        "\n",
        "# define dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/mhmmd-nauman/DataSets/master/black-box-models/CP-Nets/wpbc/original%20ds/wpbc%20-%20complete.csv')\n",
        "X = data.iloc[:, 1:34].values\n",
        "y = data['Outcome']\n",
        "\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\t# evaluate the model\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\t# store the results\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\t# summarize the performance along the way\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "ErUdPB_kf9Ok"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}